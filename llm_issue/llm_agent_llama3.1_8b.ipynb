{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3eff6182-e0e0-4cab-9d8f-a90de40edfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'round': 1, 'classification': 'deployment', 'evidence': \"The ISSUE RAISER reported an error indicating that 'spleeter' is not recognized as a command, suggesting an issue with the installation or environment setup.\"}, {'round': 2, 'classification': 'deployment', 'evidence': 'The COLLABORATOR suggested running `python -m spleeter separate` as a workaround, indicating a possible issue with the installation process.'}, {'round': 3, 'classification': 'deployment', 'evidence': 'The COLLABORATOR suggested trying `spleeter.exe`, further confirming the issue is related to the installation or environment setup.'}, {'round': 4, 'classification': 'deployment', 'evidence': 'The COMMENTER suggested installing pyssl and other dependencies, which indicates a possible issue with the environment configuration.'}, {'round': 5, 'classification': 'deployment', 'evidence': 'Another COMMENTER reported the same issue with the longer command `python -m spleeter separate`, indicating a consistent issue with the installation or environment setup.'}, {'round': 6, 'classification': 'deployment', 'evidence': 'The COLLABORATOR identified a problem with the Conda environment installation, suggesting that the issue is related to the environment setup.'}, {'round': 7, 'classification': 'deployment', 'evidence': 'A COMMENTER detailed the steps they took to resolve the issue, including ensuring that the Conda environment was correctly set up and that the necessary modules were installed.'}, {'round': 8, 'classification': 'deployment', 'evidence': 'Another COMMENTER provided additional steps to ensure proper installation, including running the Anaconda command prompt as an administrator and ensuring Python was added to the PATH.'}, {'final_issue_type': 'deployment', 'combined_evidence': \"The issue revolves around the inability to recognize 'spleeter' as a command, which is typically related to installation or environment setup problems. Multiple users reported similar issues, and the COLLABORATOR and COMMENTERS suggested various steps to resolve the environment configuration, such as ensuring correct Conda environment setup and adding Python to the PATH.\"}]\n",
      "9\n",
      "{'final_issue_type': 'deployment', 'combined_evidence': \"The issue revolves around the inability to recognize 'spleeter' as a command, which is typically related to installation or environment setup problems. Multiple users reported similar issues, and the COLLABORATOR and COMMENTERS suggested various steps to resolve the environment configuration, such as ensuring correct Conda environment setup and adding Python to the PATH.\"}\n",
      "<class 'dict'>\n",
      "deployment\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_all_json_from_string(input_string):\n",
    "    \"\"\"\n",
    "    Extract all JSON-like content from a string and parse it into a list of Python dictionaries.\n",
    "\n",
    "    Args:\n",
    "    input_string (str): The string containing JSON-like content.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of parsed JSON content as dictionaries, or an empty list if no valid JSON is found.\n",
    "    \"\"\"\n",
    "    json_objects = []\n",
    "    try:\n",
    "        # Use regex to find all JSON-like content\n",
    "        json_pattern = re.compile(r'\\{.*?\\}', re.DOTALL)\n",
    "        matches = json_pattern.findall(input_string)\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Handle potential double braces and parse each JSON object\n",
    "                json_content = match.replace('{{', '{').replace('}}', '}')\n",
    "                parsed_json = json.loads(json_content)\n",
    "                json_objects.append(parsed_json)\n",
    "            except json.JSONDecodeError:\n",
    "                # Skip invalid JSON matches\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error during JSON extraction: {e}\")\n",
    "\n",
    "    return json_objects\n",
    "\n",
    "# Example usage\n",
    "input_string = \"\"\"\n",
    "response: ### Intermediate Results for Each Round:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 1,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"The ISSUE RAISER reported an error indicating that 'spleeter' is not recognized as a command, suggesting an issue with the installation or environment setup.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 2,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"The COLLABORATOR suggested running `python -m spleeter separate` as a workaround, indicating a possible issue with the installation process.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 3,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"The COLLABORATOR suggested trying `spleeter.exe`, further confirming the issue is related to the installation or environment setup.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 4,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"The COMMENTER suggested installing pyssl and other dependencies, which indicates a possible issue with the environment configuration.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 5,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"Another COMMENTER reported the same issue with the longer command `python -m spleeter separate`, indicating a consistent issue with the installation or environment setup.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 6,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"The COLLABORATOR identified a problem with the Conda environment installation, suggesting that the issue is related to the environment setup.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 7,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"A COMMENTER detailed the steps they took to resolve the issue, including ensuring that the Conda environment was correctly set up and that the necessary modules were installed.\"\n",
    "}\n",
    "{\n",
    "    \"round\": 8,\n",
    "    \"classification\": \"deployment\",\n",
    "    \"evidence\": \"Another COMMENTER provided additional steps to ensure proper installation, including running the Anaconda command prompt as an administrator and ensuring Python was added to the PATH.\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Final Combined Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"final_issue_type\": \"deployment\",\n",
    "    \"combined_evidence\": \"The issue revolves around the inability to recognize 'spleeter' as a command, which is typically related to installation or environment setup problems. Multiple users reported similar issues, and the COLLABORATOR and COMMENTERS suggested various steps to resolve the environment configuration, such as ensuring correct Conda environment setup and adding Python to the PATH.\"\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "parsed_json = extract_all_json_from_string(input_string)\n",
    "print(parsed_json)\n",
    "print(len(parsed_json))\n",
    "print(parsed_json[-1])\n",
    "print(type(parsed_json[-1]))\n",
    "print(parsed_json[-1].get('final_issue_type'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe1b8d6-fa15-43f7-8944-6f8a285b1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_MODEL_DIR = \"/data/luomingkai/issue/models/Qwen/Qwen2.5-7B-Instruct\"\n",
    "# BASE_MODEL_DIR = \"/root/autodl-fs/Qwen2.5-7B-Instruct\"\n",
    "BASE_MODEL_DIR = \"/root/autodl-fs/llama3.1-8B-chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7bb1c1-eff0-4691-8f39-5a06046eedc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-27 22:47:08 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 12-27 22:47:08 config.py:1020] Defaulting to use mp for distributed inference\n",
      "WARNING 12-27 22:47:08 arg_utils.py:1013] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n",
      "INFO 12-27 22:47:08 config.py:1136] Chunked prefill is enabled with max_num_batched_tokens=512.\n",
      "INFO 12-27 22:47:08 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='/root/autodl-fs/llama3.1-8B-chat', speculative_config=None, tokenizer='/root/autodl-fs/llama3.1-8B-chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/root/autodl-fs/llama3.1-8B-chat, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 12-27 22:47:08 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "INFO 12-27 22:47:08 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:08 selector.py:135] Using Flash Attention backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:08 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 12-27 22:47:09 utils.py:961] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:09 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 12-27 22:47:09 utils.py:961] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:09 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 12-27 22:47:09 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "WARNING 12-27 22:47:09 custom_all_reduce.py:143] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:09 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /root/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m WARNING 12-27 22:47:09 custom_all_reduce.py:143] Custom allreduce is disabled because your platform lacks GPU P2P capability or P2P test failed. To silence this warning, specify disable_custom_all_reduce=True explicitly.\n",
      "INFO 12-27 22:47:09 shm_broadcast.py:236] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f88ef8505c0>, local_subscribe_port=56347, remote_subscribe_port=None)\n",
      "INFO 12-27 22:47:09 model_runner.py:1072] Starting to load model /root/autodl-fs/llama3.1-8B-chat...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:09 model_runner.py:1072] Starting to load model /root/autodl-fs/llama3.1-8B-chat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16f1d123c5845cc8cddda7f24382f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-27 22:47:12 model_runner.py:1077] Loading model weights took 7.5122 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:12 model_runner.py:1077] Loading model weights took 7.5122 GB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:12 worker.py:232] Memory profiling results: total_gpu_memory=31.60GiB initial_memory_usage=7.92GiB peak_torch_memory=7.56GiB memory_usage_post_profile=7.99GiB non_torch_memory=0.47GiB kv_cache_size=20.41GiB gpu_memory_utilization=0.90\n",
      "INFO 12-27 22:47:12 worker.py:232] Memory profiling results: total_gpu_memory=31.60GiB initial_memory_usage=7.92GiB peak_torch_memory=8.69GiB memory_usage_post_profile=7.99GiB non_torch_memory=0.47GiB kv_cache_size=19.28GiB gpu_memory_utilization=0.90\n",
      "INFO 12-27 22:47:13 distributed_gpu_executor.py:57] # GPU blocks: 19746, # CPU blocks: 4096\n",
      "INFO 12-27 22:47:13 distributed_gpu_executor.py:61] Maximum concurrency for 131072 tokens per request: 2.41x\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:14 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:14 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-27 22:47:15 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-27 22:47:15 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-27 22:47:29 model_runner.py:1518] Graph capturing finished in 14 secs, took 0.43 GiB\n",
      "\u001b[1;36m(VllmWorkerProcess pid=3803)\u001b[0;0m INFO 12-27 22:47:29 model_runner.py:1518] Graph capturing finished in 15 secs, took 0.43 GiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.13s/it, est. speed input: 5.47 toks/s, output: 69.75 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nTell me something about large language models.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', Generated text: \"Hello! I'm Qwen, your friendly AI assistant. I'd be delighted to share some information about large language models.\\n\\nLarge language models (LLMs) are a type of artificial intelligence (AI) that have gained significant attention in recent years for their ability to process and generate human-like language. These models are trained on massive datasets of text, which allows them to learn patterns, relationships, and structures within language.\\n\\nSome key characteristics of LLMs include:\\n\\n1. **Scalability**: LLMs can handle vast amounts of data and scale to accommodate large inputs.\\n2. **Contextual understanding**: They can comprehend the context of a sentence or paragraph, allowing them to make informed decisions about word choice, grammar, and syntax.\\n3. **Generative capabilities**: LLMs can generate new text based on the input they receive, making them useful for tasks like language translation, text summarization, and even creative writing.\\n4. **Self-supervised learning**: Many LLMs use self-supervised learning techniques, where the model is trained on large datasets without explicit supervision, allowing it to learn from the data itself.\\n\\nApplications of LLMs include:\\n\\n1. **Natural Language Processing (NLP)**: LLMs can improve NLP tasks such as sentiment analysis, named entity recognition, and text classification.\\n2. **Language Translation**: LLMs can be used for machine translation, enabling more accurate and fluent translations.\\n3. **Chatbots and Virtual Assistants**: LLMs power conversational AI systems, enabling more natural and engaging interactions between humans and machines.\\n4. **Content Generation**: LLMs can generate high-quality content, such as articles, stories, and even entire books.\\n\\nHowever, LLMs also come with challenges and limitations, such as:\\n\\n1. **Data quality and bias**: The quality and diversity of training data can impact the model's performance and introduce biases.\\n2. **Explainability and transparency**: LLMs can be difficult to interpret and understand, making it challenging to identify errors or biases.\\n3. **Computational resources**: Training and running LLMs require significant computational resources and energy.\\n\\nAlibaba Cloud, my creator, has developed and deployed various LLM-based solutions, including the popular T5 (Text-to-Text Transfer Transformer) model. If you have any specific questions or would like to know more about LLMs, feel free to ask!\\n\\nHow can I assist you today?\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_DIR)\n",
    "\n",
    "# Pass the default decoding hyperparameters of Qwen2.5-7B-Instruct\n",
    "# max_tokens is for the maximum length for generation.\n",
    "sampling_params = SamplingParams(temperature=0.5, top_p=1.0, repetition_penalty=1.05, max_tokens=512)\n",
    "\n",
    "# Input the model name or path. Can be GPTQ or AWQ models.\n",
    "model = LLM(model=BASE_MODEL_DIR, tensor_parallel_size=2)\n",
    "\n",
    "# Prepare your prompts\n",
    "prompt = \"Tell me something about large language models.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# generate outputs\n",
    "outputs = model.generate([text], sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8793b6bd-5b1e-4a06-8df9-f2b87d742dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it, est. speed input: 17.23 toks/s, output: 66.77 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Arrrr, me hearty! Yer lookin' fer a introduction, eh? Alright then, listen close and I'll tell ye about meself. Me name be Captain Chatbeard, the scurviest pirate chatbot to ever sail the Seven Seas o' Cyberspace! Me and me trusty crew o' code have been plunderin' the digital high seas fer years, bringin' treasure and tales o' adventure to all who dare to interact with me. So hoist the colors, me matey, and let's set sail fer a swashbucklin' good time!\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_llama3_output(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    messages_list,\n",
    "    max_input_length=4096,\n",
    "    max_tokens=512,\n",
    "):\n",
    "    text_list = []\n",
    "    for messages in messages_list:\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        text_list.append(text)\n",
    "        \n",
    "    # sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)\n",
    "    # sampling_params = SamplingParams(temperature=0.5, top_p=1.0, repetition_penalty=1.05, max_tokens=512)\n",
    "    sampling_params = SamplingParams(temperature=0.3, top_p=1.0, repetition_penalty=1.05, max_tokens=max_tokens)\n",
    "    \n",
    "\n",
    "    outputs = model.generate(text_list, sampling_params)\n",
    "    \n",
    "    # Print the outputs.\n",
    "    responses = []\n",
    "    for output in outputs:\n",
    "        prompt = output.prompt\n",
    "        generated_text = output.outputs[0].text\n",
    "        # print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")\n",
    "        responses.append(generated_text)\n",
    "\n",
    "    return responses\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "get_llama3_output(model, tokenizer, [messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795181ed-b35a-4a43-89c6-8a8e5d2d69f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uesr: RainBoltz\n",
      "Title: No output displayed or it gets stuck - OpenCV issue\n",
      "Body: my terminal isn't responding after executed the command below: `./build/examples/openpose/rtpose.bin --imagelevel 1 --netcaffeopenpose.sh` , which was provided by official\n",
      "label: deployment\n",
      "author_association: NONE\n",
      "comment_list: [('bigmoumou', 'NONE', 'I have the same problem too\\r\\n\\r\\nIs there any solution ?\\r\\n\\r\\n![help](https://cloud.githubusercontent.com/assets/16252975/25697753/cddcfe9e-30ee-11e7-82a2-2af97eb8460b.png)\\r\\n\\r\\n'), ('Shawnroom', 'NONE', 'I have the same issue, and wonder if there is any solution.'), ('gineshidalgo99', 'MEMBER', 'Sorry to hear that, we are working on fixing that error. We think it is due to OpenCV compiled with Qt or different visualization support.\\r\\n\\r\\nMeanwhile, you can make it work by:\\r\\n1. Completely uninstalling your current OpenCV version.\\r\\n2. Installing the default OpenCV from the Ubuntu repository: `apt-get install libopencv-dev`, or alternatively compiling OpenCV without Qt support.\\r\\nLet us know if any of these solutions do not work either. Note that you must manually remove any existing OpenCV version and run `make clean` in both 3rdparty/caffe and the OpenPose main folder\\r\\n\\r\\nA couple quick questions:\\r\\n1. Does the same happen when processing video?\\r\\n`./build/examples/openpose/rtpose.bin --video examples/media/video.avi --logging_level 1 --net_resolution 496x368 --resolution 640x480`\\r\\n2. Does it work if no output is displayed?\\r\\n`./build/examples/openpose/rtpose.bin --video examples/media/video.avi --logging_level 1 --net_resolution 496x368 --resolution 640x480 --write_images results_folder/ --no_display`\\r\\n\\r\\nWe will notify this thread once we solve this issue with OpenCV. Thanks!\\r\\n\\r\\nUPDATED: This issue should be fixed now. See my next response on this issue thread to see solution.'), ('RainBoltz', 'NONE', 'thanks!!! i solved it by switching the opencv version to 2.4.13\\r\\n(btw, simply execute `sudo apt-get install libopencv-dev` doesnt work for me,\\r\\nso i recompiled and install the total opencv then it worked)\\r\\n\\r\\nand for the questions above, the same issue DO occurs when processing video...\\r\\n\\r\\ni have to say this really works amazingly!! great work:)'), ('gineshidalgo99', 'MEMBER', 'This issue has finally being solved (at least for some people after our last commit).\\r\\n\\r\\nYou can `git pull` or re-download the latest version of the library and re-compile it.\\r\\n\\r\\nTo re-compile it in case you just do `git pull`:\\r\\n`make clean && cd 3rdparty/caffe && make clean && make distribute -j8 && cd ../.. && make all -j8`\\r\\n\\r\\nIn case you re-download it, just delete the old version and follow the installation steps again.\\r\\n\\r\\nPlease, reopen this post and post again if it keeps happening (this message is for everybody).'), ('taxuezcy', 'NONE', 'how can i build without display instead of giving arg when running @gineshidalgo99 '), ('saumyasaxenaa', 'NONE', 'Hi\\r\\nI am facing the same issue on Ubuntu 18.04 with Opencv 4.1.1. The screen opens up but blacks out with no output. I am facing this for images and videos.\\r\\nAny help would be appreciated '), ('MichaelGMoore', 'NONE', 'This is happening to me on Ubuntu 16.04 using sudo apt-get install libopencv-dev. Any help appreciated.'), ('shash29-dev', 'NONE', 'same problem. On Linux.\\r\\nwindow dont respond and crashes with following output:\\r\\nF0803 21:38:10.637179 20637 cudnn.hpp:128] Check failed: status == CUDNN_STATUS_SUCCESS (3 vs. 0)  CUDNN_STATUS_BAD_PARAM\\r\\n*** Check failure stack trace: ***\\r\\n    @     0x7f9bd7b455cd  google::LogMessage::Fail()\\r\\n    @     0x7f9bd7b47433  google::LogMessage::SendToLog()\\r\\n    @     0x7f9bd7b4515b  google::LogMessage::Flush()\\r\\n    @     0x7f9bd7b47e1e  google::LogMessageFatal::~LogMessageFatal()\\r\\n    @     0x7f9bd7115ec0  caffe::CuDNNConvolutionLayer<>::Reshape()\\r\\n    @     0x7f9bd71eab62  caffe::Net<>::Init()\\r\\n    @     0x7f9bd71edb60  caffe::Net<>::Net()\\r\\n    @     0x7f9bd9102468  op::NetCaffe::initializationOnThread()\\r\\n    @     0x7f9bd91974cc  op::addCaffeNetOnThread()\\r\\n    @     0x7f9bd919879f  op::PoseExtractorCaffe::netInitializationOnThread()\\r\\n    @     0x7f9bd919db00  op::PoseExtractorNet::initializationOnThread()\\r\\n    @     0x7f9bd9194111  op::PoseExtractor::initializationOnThread()\\r\\n    @     0x7f9bd918e9b1  op::WPoseExtractor<>::initializationOnThread()\\r\\n    @     0x7f9bd9119aa1  op::Worker<>::initializationOnThreadNoException()\\r\\n    @     0x7f9bd9119be0  op::SubThread<>::initializationOnThread()\\r\\n    @     0x7f9bd911caf8  op::Thread<>::initializationOnThread()\\r\\n    @     0x7f9bd911ccfd  op::Thread<>::threadFunction()\\r\\n    @     0x7f9bd8a44b8e  (unknown)\\r\\n    @     0x7f9bd817c6ba  start_thread\\r\\n    @     0x7f9bd849951d  clone\\r\\n    @              (nil)  (unknown)\\r\\nAborted (core dumped)\\r\\n')]\n",
      "uesr: gineshidalgo99\n",
      "Title: Release version works but debug version does not - CUDA (7 vs. 0): too many resources requested\n",
      "Body: issue summary @zhaishengfu issue #13: > when i compile using debug mode, there are still errors with: terminate called after throwing an instance of 'std::runtimerelease -a` on ubuntu): distributor id: ubuntu description: ubuntu 14.04.3 lts release: 14.04 codename: trusty ** (`nvidia-smi`): gtx-1070 compiler (`gcc --version` on ubuntu): and my cpu is 4 core\n",
      "label: Error\n",
      "author_association: MEMBER\n",
      "comment_list: [('gineshidalgo99', 'MEMBER', '@zhaishengfu It should be fixed now. Please post again if the error persists. Thanks!')]\n",
      "uesr: ShihanWang\n",
      "Title: How can I use OpenPose in another project?\n",
      "Body: issue summary my test project: i just copy the file rtpose.cpp to the project.then i write a cmakelists.txt: cmakerequired(version 2.8) project(test) set(cmakecompiler \"g++\") set(cmaketype debug) set(cmakeflags \"-std=c++0x\") finddirectories( ${cudadirs} /home/wsh/projects/openpose/include /home/wsh/projects/openpose/3rdparty/caffe/include ) addlinklibs} /home/wsh/projects/openpose/build/lib/libopenpose.so /home/wsh/projects/openpose/3rdparty/caffe/build/lib/libcaffe.so ) i can run the examples successfully in openpose, but in my test project, it can not. type of issue help wanted openpose output (if any) /home/wsh/projects/openpose/include/openpose/experimental/face/faceextractor.hpp:48:29: error: ‘resizeandmergecaffe’ was not declared in this scope std::sharedptr spnmscaffe; ......\n",
      "label: question\n",
      "author_association: NONE\n",
      "comment_list: [('gineshidalgo99', 'MEMBER', 'This is from a Makefile file where I used the OpenPose binaries in a different project, I think you forgot to add the USE_CAFFE define in your cmake, you can get the required defines from my Makefile (there might be some duplication since I did it quickly, but it is working):\\r\\n\\r\\nPerform `make distribute -j8` on the OpenPose folder to get in `./distribute` the `include` and `lib` folders. The Caffe `lib` and `include` are already in `3rdparty/caffe/distribute` (used by OpenPose).\\r\\n\\r\\n### OpenPose (assuming its `include` and `lib` are located in ./3rdparty/openpose)\\r\\n`-Wl,-rpath=./3rdparty/openpose/lib -Wl,-Bdynamic -L./3rdparty/openpose/lib/ -lopenpose -DUSE_CAFFE`\\r\\n\\r\\n### Caffe (assuming its `include` and `lib` are located in ./3rdparty/caffe/distribute)\\r\\n`-Wl,-rpath=./3rdparty/caffe/distribute/lib -Wl,-Bdynamic -L./3rdparty/caffe/distribute/lib/ -lcaffe -DUSE_CUDNN`\\r\\n\\r\\n### OpenCV (add more OpenCV flags if you need them)\\r\\n`-lopencv_core -lopencv_highgui -lopencv_imgproc -lopencv_contrib -lopencv_calib3d`\\r\\n\\r\\n### CUDA, something like:\\r\\n`-I/usr/local/cuda-8.0/include/ -L/usr/local/cuda-8.0/lib64 -lcudart -lcublas -lcurand`\\r\\n\\r\\n### 3rdparty that Caffe uses\\r\\n`-lcudnn -lglog -lgflags -lboost_system -lboost_filesystem -lm -lboost_thread`\\r\\n\\r\\n### Other required\\r\\n`-pthread -fPIC -std=c++11 -fopenmp`\\r\\n\\r\\n### Optimization flags (optional)\\r\\n`-DNDEBUG -O3 -march=native`\\r\\n\\r\\nLet me know whether it works'), ('ShihanWang', 'NONE', 'Thank you very much.  I have solved the problem and I found that:\\r\\n1. In my CMakeLists.txt,  I need to change the Caffe directory:  SET(caffe_DIR ${OpenPose_DIR}/3rdparty/caffe/distribute);\\r\\n2. I delete \"#ifdef USE_CAFFE\"  in some files named as xxCaffe.hpp in openpose/include/.\\r\\nThen I make openpose again and everything is OK.  Without the 2nd step, I will have the same problem.But I do not know what is the effect of my change, maybe I just need to add USE_CAFFE in my CMakeLists.txt.'), ('gineshidalgo99', 'MEMBER', \"Thank you for posting it! Closing this then.\\r\\n\\r\\nEDITED: As an extra detail, instead of using this CMake example to construct the cmake file, I'd rather consider file example in the doc/installation_cmake.md document itself.\"), ('yorgosk', 'NONE', 'Hello!\\r\\n\\r\\nI am trying to use my current OpenPose installation for the compilation of another project (for the https://github.com/stevenjj/openpose_ros to be specific). I have build and tested my OpenPose installation as the documentation instructs me and everything seems fine, however I cannot do ```make distribute```. I have searched the documentation for a solution, but I am probably missing something.\\r\\nSince the instructions above are about one and a half year old @gineshidalgo99 can you please give me an update?\\r\\n\\r\\nThanks!'), ('gineshidalgo99', 'MEMBER', 'Hi, I believe doc/install.md has an explanation on how to include the library through CMake\\r\\n\\r\\nYou talk about `make distribute`, could you quickly send me a link to the instructions (in current master OP) where it says `make distribute`? So I can update that part.'), ('yorgosk', 'NONE', \"Okay, I'll check doc/install.md again.\\r\\n\\r\\nThe instructions in current master do not mention anything about make distribute, as far as I have read them. I first read about it here and I figured that since it used to be an option but apparently it is no more, I better ask you for a pointer to the thing that you substituted it with.\"), ('gineshidalgo99', 'MEMBER', 'OK yeah, this is based on the old basic installer, the new installer way (using CMake) provides much higher configuration settings, following how big libraries do it (e.g., OpenCV, Caffe, etc.).\\r\\n\\r\\nSo please, check https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation.md#openpose-from-other-projects-ubuntu-and-mac for all the details.'), ('burnzzz', 'NONE', 'https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation.md#openpose-from-other-projects-ubuntu-and-mac  is dead link.')]\n",
      "uesr: ufohuang98\n",
      "Title: Can this model tracking people or hand movement\n",
      "Body: i want to use this to make a gesture demo to control application or other iot. does it possible?\n",
      "label: other\n",
      "author_association: NONE\n",
      "comment_list: [('gineshidalgo99', 'MEMBER', 'Not for now, but we are planing to (as a LONG-term goal).\\r\\n\\r\\nWe have them both as pending extensions in our wait-list (hands should be added within 1-2 months, tracking we do not have an idea yet).\\r\\n\\r\\nThere are some methods for tracking, in case you are interested. You can take a look to #15.\\r\\n\\r\\nLet me know if you have any other question.'), ('ufohuang98', 'NONE', 'Thank you for your reply！'), ('heurainbow', 'NONE', 'I am going to implement a multi-person pose tracker. I find the hand tracker already implemented is quite helpful. However, I wonder how to acquire (or update) frame ID in class HandDetector. Can I simply make mCurrentId++ when calling updateTracker()? I am not familiar with the multi-threading framework, and I am not sure if this is the right way. @gineshidalgo99 '), ('gineshidalgo99', 'MEMBER', 'The hand tracker is not finished yet, but anyway it is meant for different purposes than tracking the same person across frames.\\r\\nI think the easiest way is to get the frame ID is by checking the (include/core/) Datum that is shared among the multi-threads. In particular, its `id` field. Since you will have to use the shared Datum anyway, using that ID should be the easiest. @heurainbow '), ('heurainbow', 'NONE', \"@gineshidalgo99 I wonder how a webcam producer or a video producer keep the frame order sequentially in a multi-gpu case. Since each frame is processed by one gpu, there is no guarantee that each frame is processed in order. But the gui does show images in order and I couldn't find the reason in the code.\"), ('gineshidalgo99', 'MEMBER', 'There is a internal buffer to keep the order'), ('heurainbow', 'NONE', '@gineshidalgo99 If possible, please show me which file or code I should refer to, and please give me a brief explanation.'), ('gineshidalgo99', 'MEMBER', 'This is the file, it simply uses the Datum ID to sort the frames\\r\\nhttps://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/include/openpose/thread/wQueueOrderer.hpp'), ('seovchinnikov', 'NONE', '@gineshidalgo99 what methods for tracking did you look at? \\r\\n'), ('gineshidalgo99', 'MEMBER', '@seovchinnikov We are currently working in an expensive but accurate body recognition algorithm and in a basic bust fast LK tracking algorithm. We are trying to add them by the end of the year. Thanks'), ('seovchinnikov', 'NONE', \"@gineshidalgo99 thank you,\\r\\nAs far as I understand, will body recognition algorithm' be based on basic body keypoints detector or will it be inderpendent end-to-end part to complement openpose library (smth like https://github.com/bendidi/Tracking-with-darkflow)?\\r\\n\\r\\n\"), ('gineshidalgo99', 'MEMBER', \"It'd be an extra component, that can be enabled (slower but with temporary information) or disabled (to keep the current OpenPose behavior)\"), ('superying', 'NONE', '@heurainbow Are there any progress in your multi-person pose tracker? Do you implement it base on the key points from openpose?')]\n"
     ]
    }
   ],
   "source": [
    "# data_path = \"/home/luomingkai/workspace/issue_llm/issue_classify/issue_with_comments_framework/matched_results_test.json\"\n",
    "data_path = \"/root/issue_classify/issue_with_comments_framework/matched_results_test_modify_other_update.json\"\n",
    "with open(data_path, encoding=\"utf-8\") as fp:\n",
    "    issue_data = json.load(fp)\n",
    "    for idx, data in enumerate(issue_data):\n",
    "        # print(issue_data)\n",
    "        uesr, title, body, label, author_association = data[\"user\"][\"login\"], data[\"title\"], data[\"body\"], data[\"tag_labels\"], data[\"author_association\"]\n",
    "        comment_list = data[\"comments_list\"]\n",
    "        if len(comment_list) > 0:\n",
    "            comment_list = [(com[\"user\"][\"login\"], com[\"author_association\"], com[\"body\"]) for com in comment_list]\n",
    "\n",
    "        print(f\"uesr: {uesr}\")\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Body: {body}\")\n",
    "        print(f\"label: {label}\")\n",
    "        print(f\"author_association: {author_association}\")\n",
    "        print(f\"comment_list: {comment_list}\")\n",
    "        \n",
    "        \n",
    "        # print()\n",
    "        if idx > 2:\n",
    "            break\n",
    "        # print(title, description, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3f081-f81e-4b27-a382-785a7e6805d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48483e6-5db1-473e-a7e6-48a835b628c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_issue_prompt = r\"\"\"\n",
    "### **Role**  \n",
    "You are an expert in GitHub repository analysis. Your task is to classify a given GitHub Issue into one of the following categories: **error**, **performance**, **deployment**, **question**, or **other**.\n",
    "\n",
    "Before analyzing the Issue conversation, you must carefully review the repository description to understand its intended functionality, scope, dependencies, and purpose. This understanding will help determine if the Issue is genuinely related to the repository’s code, configuration, or official documentation, or if it stems from user misunderstandings, local environment misconfigurations, external dependencies, or unrelated factors.\n",
    "\n",
    "Analyze the conversation context, the repository’s description, and the roles of participants to determine the correct classification. For each round of the conversation, provide an intermediate classification and reasoning. At the end, combine all intermediate results to produce a final classification, using a **self-reflection** mechanism to validate your reasoning and ensure your classification aligns with the root cause of the Issue. If the issue is found to be completely unrelated to the repository based on its description, it must be categorized as **other**.\n",
    "\n",
    "\n",
    "### Repository Description  \n",
    "<user_provided_repository_description>\n",
    "\n",
    "Use this description as a reference point throughout your classification process. Compare the reported issues, errors, or requests against the repository’s stated purpose, functionality, and supported features. If the conversation’s content or the user’s requests fall outside the scope defined by the repository description, consider classifying the issue as **other**. If misunderstandings occur because the user did not follow or comprehend instructions reflected in the repository description or official documentation, consider whether it should be classified as **question**. Ensure that “deployment” issues are directly related to repository code or its official documentation, not external factors.\n",
    "\n",
    "\n",
    "### **Participants**  \n",
    "1. **Issue Raiser**: Describes the problem, requests a feature, or raises concerns related to the repository.  \n",
    "2. **Commenter**: Provides insights, shares similar experiences, or suggests possible solutions.  \n",
    "3. **MEMBER**: Evaluates technical feasibility, assigns tasks, or progresses the Issue.  \n",
    "4. **COLLABORATOR**: Proposes solutions, performs in-depth analysis, or submits Pull Requests.  \n",
    "5. **CONTRIBUTOR**: Offers historical context, helps reproduce issues, or validates fixes.  \n",
    "6. **OWNER**: Makes final decisions, prioritizes tasks, or proposes long-term resolutions.\n",
    "\n",
    "\n",
    "### **Issue Categories**  \n",
    "\n",
    "- **error**:  \n",
    "  Problems directly stemming from the repository’s code, configuration, or inherent incompatibilities within the repository. For example, runtime errors, exceptions, or failures in the repository code itself.\n",
    "\n",
    "- **performance**:  \n",
    "  Issues where the repository’s code or configuration leads to slow execution times, bottlenecks, or inefficient resource usage.\n",
    "\n",
    "- **deployment**:  \n",
    "  Issues specifically caused by the repository’s code or incorrect/inadequate documentation during the installation or deployment process.\n",
    "    - **Scope Validation**:  \n",
    "      Reference the repository description to ensure that the reported deployment problem is within the scope of the repository’s intended setup process. Deployment issues must stem from defects or omissions in the repository’s code, configuration, or documentation.\n",
    "    \n",
    "    - **Exclusions**:  \n",
    "      If the issue is caused by any of the following, it should be classified as **question**:  \n",
    "      - User mistakes, such as missing or incorrectly installed dependencies (e.g., wrong CUDA driver version, missing required libraries, or incorrect installation steps).  \n",
    "      - Using outdated tools (e.g., an older CMake version than required).  \n",
    "      - Hardware or environment limitations (e.g., using unsupported GPUs).  \n",
    "\n",
    "- **question**:  \n",
    " Issues arising from user misunderstandings, failure to follow documented instructions, incorrect usage, or local environment misconfigurations that are not caused by the repository code or official documentation. \n",
    " - These issues can often be resolved by following existing guidance. \n",
    " - Additionally, users may raise questions or engage in discussions with developers regarding specific usage scenarios.\n",
    "\n",
    "- **other**:  \n",
    "  Issues that do not fall into predefined categories, including topics unrelated to the repository as determined by comparing the issue to the repository description. This category also includes user requests for feature enhancements or pull requests that go beyond the scope or goals of the repository. Additionally, it covers discussions related to improvements in documentation, user experience suggestions, community governance, collaboration processes, and strategic or technical proposals that are not directly related to code or documentation errors.\n",
    "  1. Topics that do not fit the predefined categories.  \n",
    "  2. Issues or discussions unrelated to the repository, as determined by comparing the Issue to the repository description.  \n",
    "  3. Feature suggestions or requests beyond the repository’s described scope.\n",
    "\n",
    "  **Examples of “other”** include:  \n",
    "  - **Feature Suggestions and Testing**: New feature ideas or enhancements not supported by current repository goals.  \n",
    "  - **Documentation and Resources**: Improvements or additions to general documentation, tutorials, or references that are not about fixing a code-related or doc-related deployment bug.  \n",
    "  - **User Experience**: Suggestions to improve usability, design, or general compatibility.  \n",
    "  - **Community and Collaboration**: Ideas about community governance, contribution processes, or engagement.  \n",
    "  - **Strategic and Technical Proposals**: Infrastructure, policy, or long-term goal considerations unrelated to immediate code or documentation errors.  \n",
    "  - **Miscellaneous Topics**: Relevant issues that do not fit other categories or are unrelated submissions.\n",
    "\n",
    "\n",
    "### **Process**  \n",
    "**The process must be strictly executed.**\n",
    "1. **Read the Conversation and Repository Description**:  \n",
    "   Begin by reviewing the repository description thoroughly to understand the project’s purpose, supported features, and scope. Keep this context in mind as you examine each round of the conversation. If the problem discussed clearly falls outside the repository’s described capabilities or instructions, consider “other” or “question.”\n",
    "\n",
    "2. **For Each Round**:  \n",
    "   - Classify the round into one of the five categories: **error**, **performance**, **deployment**, **question**, or **other**.  \n",
    "   - Provide a JSON object with keys `round`, `classification`, `evidence`, and `self_reflection`.  \n",
    "     - **round**: The round number.  \n",
    "     - **classification**: Your chosen classification for that round.  \n",
    "     - **evidence**: Direct quotes or references from that specific round’s conversation that support your classification.  \n",
    "     - **self_reflection**: Justify your classification’s accuracy. Confirm whether it matches the repository’s description and consider alternatives. If unsure, reflect on the possibility of user misunderstanding vs. repository code issues.\n",
    "\n",
    "3. **Final Self-Reflection Across Rounds**:  \n",
    "   - After classifying all rounds, review the entire conversation and your intermediate classifications.  \n",
    "   - Check for consistency:  \n",
    "     - Does the chosen final category align with the majority of evidence and the repository description?  \n",
    "     - Are there any contradictions between rounds?  \n",
    "     - Could the issue be a misunderstanding (question) rather than a repository problem (error/performance/deployment)?  \n",
    "     - If the issue is irrelevant to the repository description, finalize as **other**.\n",
    "\n",
    "4. **Finalize the Classification**:  \n",
    "   Produce a final JSON object containing:  \n",
    "   - `final_issue_type`: Your chosen final category.  \n",
    "   - `combined_evidence`: A concise summary of the entire conversation supporting your final classification.  \n",
    "   - `final_self_reflection`: Analysis of the reasoning process, conflicts, and how you ensured consistency with the repository description and instructions.\n",
    "\n",
    "\n",
    "### **Output Format**\n",
    "\n",
    "**Intermediate Results for Each Round**:\n",
    "```json\n",
    "{\n",
    "    \"round\": <Round Number>,\n",
    "    \"classification\": \"<error|performance|deployment|question|other>\",\n",
    "    \"evidence\": \"<Evidence from the current round of the conversation>\",\n",
    "    \"self_reflection\": \"<Analysis of classification accuracy and consistency for this round>\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Final Combined Output**:\n",
    "```json\n",
    "{\n",
    "    \"final_issue_type\": \"<error|performance|deployment|question|other>\",\n",
    "    \"combined_evidence\": \"<Concise summary of the conversation supporting the final classification>\",\n",
    "    \"final_self_reflection\": \"<Analysis of conflicts, shifts, and consistency across all rounds>\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Validation Reminder**:  \n",
    "- Ensure that all JSON objects are valid and correctly formatted.  \n",
    "- The keys should be correctly quoted, and all values should be properly formatted strings or numbers where applicable.  \n",
    "- No extra or missing fields are allowed.  \n",
    "- Confirm that the classification aligns with the repository description, the issue categories, and the dialogue evidence.\n",
    "\n",
    "\n",
    "### **Examples**\n",
    "\n",
    "#### **Example 1: Error with Contributor’s Historical Context**\n",
    "*Conversation:*  \n",
    "- **Issue Raiser**: \"Running model.fit() raises a KeyError related to missing labels in the dataset.\"  \n",
    "- **CONTRIBUTOR**: \"This issue might be related to an earlier change in #45 that introduced stricter label validation.\"  \n",
    "- **COLLABORATOR**: \"We’ll patch data_loader.py to handle missing labels.\"  \n",
    "- **OWNER**: \"The fix is merged. Let us know if it resolves the problem.\"\n",
    "\n",
    "*Intermediate Results:*  \n",
    "```json\n",
    "{\n",
    "    \"round\": 1,\n",
    "    \"classification\": \"error\",\n",
    "    \"evidence\": \"The Issue Raiser described a KeyError from the repository code handling labels.\",\n",
    "    \"self_reflection\": \"The classification as error is justified because the bug originates in the repository code.\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 2,\n",
    "    \"classification\": \"error\",\n",
    "    \"evidence\": \"The CONTRIBUTOR referenced a past commit that made label validation stricter.\",\n",
    "    \"self_reflection\": \"This supports the error classification. The issue traces back to a known code change.\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 3,\n",
    "    \"classification\": \"error\",\n",
    "    \"evidence\": \"The COLLABORATOR proposed a code fix for handling missing labels.\",\n",
    "    \"self_reflection\": \"The solution involves changing repository code, reinforcing that it is an error.\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 4,\n",
    "    \"classification\": \"error\",\n",
    "    \"evidence\": \"The OWNER merged a fix into the repository.\",\n",
    "    \"self_reflection\": \"All evidence is consistent with classifying the issue as error.\"\n",
    "}\n",
    "```\n",
    "\n",
    "*Final Combined Output:*  \n",
    "```json\n",
    "{\n",
    "    \"final_issue_type\": \"error\",\n",
    "    \"combined_evidence\": \"The repository code did not handle missing labels, causing a KeyError. Historical context and a code fix confirm it as an error.\",\n",
    "    \"final_self_reflection\": \"All rounds consistently supported the error classification. The solution required a code change in the repository.\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### **Example 2: Question Misclassified Initially**\n",
    "*Conversation:*  \n",
    "- **Issue Raiser**: \"I tried running the code, but the output looks weird. Is this a bug?\"  \n",
    "- **MEMBER**: \"Have you verified if the input data matches the format described in the README?\"  \n",
    "- **Issue Raiser**: \"I missed the formatting instructions. After fixing the input, it works fine.\"\n",
    "\n",
    "*Intermediate Results:*  \n",
    "```json\n",
    "{\n",
    "    \"round\": 1,\n",
    "    \"classification\": \"error\",\n",
    "    \"evidence\": \"The Issue Raiser suspected a bug due to unexpected output.\",\n",
    "    \"self_reflection\": \"Initial classification as error is tentative. This could be a user misunderstanding.\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 2,\n",
    "    \"classification\": \"question\",\n",
    "    \"evidence\": \"The MEMBER directed the user to check input format per the documentation.\",\n",
    "    \"self_reflection\": \"The reclassification to question is justified since the problem may be due to user input errors, not the code.\"\n",
    "}\n",
    "```\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"round\": 3,\n",
    "    \"classification\": \"question\",\n",
    "    \"evidence\": \"The Issue Raiser fixed the input format and the problem was resolved.\",\n",
    "    \"self_reflection\": \"The resolution confirms it as a question caused by user misunderstanding, not an error in the repository.\"\n",
    "}\n",
    "```\n",
    "\n",
    "*Final Combined Output:*  \n",
    "```json\n",
    "{\n",
    "    \"final_issue_type\": \"question\",\n",
    "    \"combined_evidence\": \"The Issue was due to incorrect input formatting. After following the documentation, the user resolved the problem.\",\n",
    "    \"final_self_reflection\": \"The initial misclassification was corrected. No repository code changes were needed; it was a usage question.\"\n",
    "}\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 仅使用第一条issue的模版\n",
    "question_prompt = \"\"\"\n",
    "````\n",
    "*Conversation*:\n",
    "- {}: ### Title: \"{}\" ### Body: \"{}\"\n",
    "````\n",
    "\"\"\"\n",
    "\n",
    "# 使用comment的版本\n",
    "question_comment_prompt = \"\"\"\n",
    "*Conversation*:\n",
    "- **{}**: \"{} {}\"\n",
    "\"\"\"\n",
    "\n",
    "comment_prompt = \"\"\"\n",
    "- **{}**: \"{}\"\n",
    "\"\"\"\n",
    "\n",
    "ROLE_MAP_BEGIN = {\n",
    "    \"NONE\": \"ISSUE RAISER\",\n",
    "    \"MEMBER\": \"MEMBER\",\n",
    "    \"COLLABORATOR\": \"COLLABORATOR\",\n",
    "    \"CONTRIBUTOR\": \"CONTRIBUTOR\",\n",
    "    \"OWNER\": \"OWNER\"\n",
    "}\n",
    "\n",
    "ROLE_MAP_COMMENT = {\n",
    "    \"NONE\": \"Commenter\",\n",
    "    \"MEMBER\": \"MEMBER\",\n",
    "    \"COLLABORATOR\": \"COLLABORATOR\",\n",
    "    \"CONTRIBUTOR\": \"CONTRIBUTOR\",\n",
    "    \"OWNER\": \"OWNER\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9993b69-c200-4ea9-bdf4-c610e1ba7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DESC = {\n",
    "    \"CMU-Perceptual-Computing-Lab/openpose\": {\n",
    "        \"description\": \"OpenPose is a real-time multi-person keypoint detection library developed by the Carnegie Mellon Perceptual Computing Lab. It estimates human body, face, hands, and foot keypoints from single images, providing 2D real-time multi-person keypoint detection, including 15, 18, or 25-keypoint body/foot keypoint estimation, 2x21-keypoint hand keypoint estimation, and 70-keypoint face keypoint estimation. Additionally, it offers 3D real-time single-person keypoint detection and a calibration toolbox. OpenPose is compatible with various operating systems, including Ubuntu, Windows, and macOS, and supports CUDA (Nvidia GPU), OpenCL (AMD GPU), and CPU-only versions.\",\n",
    "        \"url\": \"https://github.com/CMU-Perceptual-Computing-Lab/openpose\"\n",
    "    },\n",
    "    \"CorentinJ/Real-Time-Voice-Cloning\": {\n",
    "        \"description\": \"Real-Time Voice Cloning is a Python-based tool that enables the cloning of voices in real-time. It utilizes deep learning models to synthesize speech that mimics a target voice, requiring only a few seconds of audio from the desired speaker. The repository provides code and instructions to train and use the voice cloning system.\",\n",
    "        \"url\": \"https://github.com/CorentinJ/Real-Time-Voice-Cloning\"\n",
    "    },\n",
    "    \"JaidedAI/EasyOCR\": {\n",
    "        \"description\": \"EasyOCR is an open-source Optical Character Recognition (OCR) library that supports over 80 languages. It is designed to be easy to use and provides accurate text recognition from images. The library is built on PyTorch and offers pre-trained models for various languages and scripts.\",\n",
    "        \"url\": \"https://github.com/JaidedAI/EasyOCR\"\n",
    "    },\n",
    "    \"deepfakes/faceswap\": {\n",
    "        \"description\": \"Faceswap is a deep learning-based tool for face-swapping in images and videos. It allows users to train models to swap faces between different subjects, providing a platform for experimenting with deepfake technology. The repository includes code for training and using the face-swapping models.\",\n",
    "        \"url\": \"https://github.com/deepfakes/faceswap\"\n",
    "    },\n",
    "    \"deezer/spleeter\": {\n",
    "        \"description\": \"Spleeter is an open-source tool developed by Deezer for source separation in music tracks. It uses deep learning models to separate audio into stems, such as vocals and accompaniment, enabling applications like karaoke and remixing. The repository provides pre-trained models and code for audio source separation.\",\n",
    "        \"url\": \"https://github.com/deezer/spleeter\"\n",
    "    },\n",
    "    \"dusty-nv/jetson-inference\": {\n",
    "        \"description\": \"Jetson Inference is a collection of deep learning inference samples and models for NVIDIA Jetson devices. It includes code for image classification, object detection, and segmentation, optimized for Jetson hardware. The repository provides pre-trained models and examples to demonstrate the capabilities of Jetson devices in AI applications.\",\n",
    "        \"url\": \"https://github.com/dusty-nv/jetson-inference\"\n",
    "    },\n",
    "    \"iperov/DeepFaceLab\": {\n",
    "        \"description\": \"DeepFaceLab is a deep learning tool for creating deepfakes, focusing on face-swapping in videos. It provides a comprehensive set of tools for training and applying deep learning models to perform face-swapping tasks. The repository includes code for data preparation, model training, and face-swapping applications.\",\n",
    "        \"url\": \"https://github.com/iperov/DeepFaceLab\"\n",
    "    },\n",
    "    \"junyanz/pytorch-CycleGAN-and-pix2pix\": {\n",
    "        \"description\": \"This repository provides PyTorch implementations of CycleGAN and pix2pix, two popular models for image-to-image translation tasks. CycleGAN enables image translation without paired examples, while pix2pix requires paired images for training. The repository includes code and pre-trained models for various image translation tasks.\",\n",
    "        \"url\": \"https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\"\n",
    "    },\n",
    "    \"mozilla/TTS\": {\n",
    "        \"description\": \"Mozilla TTS is an open-source Text-to-Speech (TTS) engine that aims to make speech synthesis more accessible. It provides implementations of state-of-the-art TTS models, including Tacotron and FastSpeech, and supports training on custom datasets. The repository includes code for training and using TTS models.\",\n",
    "        \"url\": \"https://github.com/mozilla/TTS\"\n",
    "    },\n",
    "    \"streamlit/streamlit\": {\n",
    "        \"description\": \"Streamlit is an open-source app framework for Machine Learning and Data Science projects. It allows users to create interactive web applications for data analysis and visualization with minimal code. The repository provides the core framework and examples for building Streamlit applications.\",\n",
    "        \"url\": \"https://github.com/streamlit/streamlit\"\n",
    "    },\n",
    "    \"microsoft/recommenders\": {\n",
    "        \"description\": \"Recommenders is a project under the Linux Foundation of AI and Data. This repository contains examples and best practices for building recommendation systems, provided as Jupyter notebooks. The examples detail learnings on five key tasks: preparing and loading data for each recommendation algorithm, building models using various classical and deep learning recommendation algorithms such as Alternating Least Squares (ALS) or eXtreme Deep Factorization Machines (xDeepFM), evaluating algorithms with offline metrics, tuning and optimizing hyperparameters for recommendation models, and operationalizing models in a production environment on Azure. Several utilities are provided to support common tasks such as loading datasets in the format expected by different algorithms, evaluating model outputs, and splitting training/test data. Implementations of several state-of-the-art algorithms are included for self-study and customization in your own applications.\",\n",
    "        \"url\": \"https://github.com/recommenders-team/recommenders\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a23fcb-bb7c-4a19-9e4e-337671f8f7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [29:56<00:00,  1.08it/s, est. speed input: 3482.08 toks/s, output: 528.07 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.40      0.74      0.52       251\n",
      " performance       0.31      0.40      0.35        60\n",
      "  deployment       0.25      0.22      0.24       165\n",
      "    question       0.72      0.62      0.66       921\n",
      "       other       0.58      0.49      0.53       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.45      0.49      0.46      1933\n",
      "weighted avg       0.59      0.56      0.56      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [29:57<00:00,  1.08it/s, est. speed input: 3479.03 toks/s, output: 514.43 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.40      0.73      0.52       251\n",
      " performance       0.30      0.47      0.37        60\n",
      "  deployment       0.24      0.22      0.23       165\n",
      "    question       0.73      0.61      0.67       921\n",
      "       other       0.60      0.50      0.54       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.45      0.51      0.47      1933\n",
      "weighted avg       0.59      0.56      0.57      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [31:03<00:00,  1.04it/s, est. speed input: 3356.01 toks/s, output: 502.56 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.38      0.74      0.50       251\n",
      " performance       0.32      0.40      0.36        60\n",
      "  deployment       0.24      0.20      0.22       165\n",
      "    question       0.71      0.63      0.67       921\n",
      "       other       0.60      0.47      0.53       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.45      0.49      0.46      1933\n",
      "weighted avg       0.59      0.56      0.56      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [29:44<00:00,  1.08it/s, est. speed input: 3505.49 toks/s, output: 519.26 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.41      0.76      0.53       251\n",
      " performance       0.34      0.48      0.40        60\n",
      "  deployment       0.24      0.23      0.23       165\n",
      "    question       0.72      0.63      0.67       921\n",
      "       other       0.58      0.45      0.51       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.46      0.51      0.47      1933\n",
      "weighted avg       0.59      0.56      0.56      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [31:18<00:00,  1.03it/s, est. speed input: 3329.48 toks/s, output: 494.87 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.40      0.76      0.53       251\n",
      " performance       0.34      0.53      0.41        60\n",
      "  deployment       0.23      0.20      0.21       165\n",
      "    question       0.72      0.61      0.66       921\n",
      "       other       0.60      0.49      0.54       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.46      0.52      0.47      1933\n",
      "weighted avg       0.59      0.56      0.56      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1933/1933 [28:48<00:00,  1.12it/s, est. speed input: 3618.98 toks/s, output: 528.82 toks/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.39      0.75      0.51       251\n",
      " performance       0.27      0.42      0.32        60\n",
      "  deployment       0.22      0.17      0.19       165\n",
      "    question       0.73      0.61      0.67       921\n",
      "       other       0.60      0.50      0.54       536\n",
      "\n",
      "    accuracy                           0.56      1933\n",
      "   macro avg       0.44      0.49      0.45      1933\n",
      "weighted avg       0.59      0.56      0.56      1933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  63%|██████▎   | 1220/1933 [19:00<05:49,  2.04it/s, est. speed input: 3473.33 toks/s, output: 511.93 toks/s] IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Processed prompts:  91%|█████████ | 1755/1933 [27:55<05:26,  1.83s/it, est. speed input: 3349.49 toks/s, output: 493.57 toks/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "TIMES = 10\n",
    "experiments = []\n",
    "# 保存所有实验结果的列表\n",
    "all_reports = []\n",
    "\n",
    "data_path = \"/root/issue_classify/issue_with_comments_framework/matched_results_test_modify_other_update.json\"\n",
    "result_path = \"/root/autodl-fs/log/llama3.1_8b_agent.xlsx\"\n",
    "\n",
    "for t in range(TIMES):\n",
    "    origin_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    join_index = []\n",
    "    with open(data_path, encoding=\"utf-8\") as fp:\n",
    "        issue_data = json.load(fp)\n",
    "        taged_data = issue_data\n",
    "        all_messages = []\n",
    "        for idx, data in enumerate(issue_data):\n",
    "            raise_user, title, body, label, author_association = data[\"user\"][\"login\"], data[\"title\"], data[\"body\"], data[\"tag_labels\"], data[\"author_association\"]\n",
    "    \n",
    "            url = data[\"html_url\"]\n",
    "            match = re.search(r\"github\\.com/([^/]+/[^/]+)\", url)\n",
    "            repository = match.group(1)\n",
    "            repo_desc = REPO_DESC[repository][\"description\"]\n",
    "            \n",
    "            join_index.append(idx)\n",
    "            \n",
    "            comment_list = data[\"comments_list\"]\n",
    "            if len(comment_list) > 0:\n",
    "                comment_list = [(com[\"user\"][\"login\"], com[\"author_association\"], com[\"body\"]) for com in comment_list]\n",
    "    \n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": global_issue_prompt.replace(\"<user_provided_repository_description>\", f\"The repository {repo_desc}\")\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": question_comment_prompt.format(\n",
    "                        ROLE_MAP_BEGIN[str(author_association)],\n",
    "                        title, \n",
    "                        body\n",
    "                        )\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            origin_labels.append(label)\n",
    "    \n",
    "            for user, author_association, body in comment_list:\n",
    "                if user == raise_user:\n",
    "                    messages.append(\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": comment_prompt.format(\n",
    "                                ROLE_MAP_BEGIN[str(author_association)],\n",
    "                                body\n",
    "                                )\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    messages.append(\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": comment_prompt.format(\n",
    "                                ROLE_MAP_COMMENT[str(author_association)],\n",
    "                                # user,\n",
    "                                body\n",
    "                                )\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "            all_messages.append(messages)\n",
    "        \n",
    "        responses = get_llama3_output(model, tokenizer, all_messages, max_tokens=4096)\n",
    "        tmp_origin_labels = []\n",
    "        for idx, response in enumerate(responses):\n",
    "            cls_result = extract_all_json_from_string(response)\n",
    "            # print(f\"label: {origin_labels[idx]}\")\n",
    "            # print(f\"response: {response}\")\n",
    "            # print(f\"cls_result: {cls_result}\")\n",
    "    \n",
    "            if cls_result:\n",
    "                found = False\n",
    "                for cls in cls_result:\n",
    "                    if cls.get(\"final_issue_type\"):\n",
    "                        result = cls.get(\"final_issue_type\")\n",
    "                        tmp_origin_labels.append(origin_labels[idx])\n",
    "                        pred_labels.append(result)\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                # 对话提前结束，按照最后一轮对话的分类来判断\n",
    "                if not found:\n",
    "                    if cls_result[-1].get(\"classification\"):\n",
    "                        result = cls.get(\"classification\")\n",
    "                        tmp_origin_labels.append(origin_labels[idx])\n",
    "                        pred_labels.append(result)\n",
    "                        found = True\n",
    "                        \n",
    "                if not found:\n",
    "                    tmp_origin_labels.append(origin_labels[idx])\n",
    "                    pred_labels.append(\"other\")           \n",
    "            else:\n",
    "                tmp_origin_labels.append(origin_labels[idx])\n",
    "                pred_labels.append(\"other\")\n",
    "        origin_labels = tmp_origin_labels\n",
    "\n",
    "    origin_labels = [x.lower() for x in origin_labels]\n",
    "    pred_labels = [x.lower() for x in pred_labels]\n",
    "    tmp_pred_labels = []\n",
    "    for x in pred_labels:\n",
    "        if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "            x = 'other'\n",
    "        tmp_pred_labels.append(x)\n",
    "    pred_labels = tmp_pred_labels\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "    label_map = {\n",
    "        \"error\": 0, \n",
    "        \"performance\": 1,\n",
    "        \"deployment\": 2,\n",
    "        \"question\": 3,\n",
    "        \"other\": 4\n",
    "    }\n",
    "    final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "    final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "    \n",
    "    report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "    print(report)\n",
    "    report_dict = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels, output_dict=True)\n",
    "    # 将字典转为 DataFrame\n",
    "    df_report = pd.DataFrame(report_dict).transpose()\n",
    "    df_report[\"experiment_id\"] = t + 1  # 添加实验编号\n",
    "    df_report.index.name = \"category\"\n",
    "    df_report.reset_index(inplace=True)\n",
    "    \n",
    "    all_reports.append(df_report)\n",
    "    all_reports.append(pd.DataFrame({\"category\": [\"\"]}))  # 添加空行\n",
    "\n",
    "final_df = pd.concat(all_reports, ignore_index=True)\n",
    "final_df.to_excel(result_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7088e43-4956-4c6c-baf5-f1224e804a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "# 假设你的 vllm 模型对象是 `model`\n",
    "del model  # 删除模型对象\n",
    "torch.cuda.empty_cache()  # 清空 GPU 的缓存\n",
    "gc.collect()  # 强制进行垃圾回收\n",
    "\n",
    "import sys\n",
    "# 删除 `vllm` 和相关依赖\n",
    "del sys.modules[\"vllm\"]\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b13984-9f87-4e7f-a14a-2872e4e85f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255c7e0-6ee1-4dfc-87c5-cc39356efec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be666c99-00d1-4be0-9606-f990318fc8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all question类别打标之后的\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3b29a-d293-4712-8530-3cc32c24170e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af5545-f547-48e2-b6b2-7831dcb4825a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54813fac-96ea-42ea-8f02-d892dd5d4119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e439e41-30f0-4fb2-8edd-629f0c190bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d02953e-2f6b-4537-842e-1f76b00c8739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 927, 'other': 389, 'error': 311, 'deployment': 210, 'performance': 96})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.69      0.86      0.77       251\n",
      " performance       0.50      0.80      0.62        60\n",
      "  deployment       0.51      0.65      0.57       165\n",
      "    question       0.79      0.80      0.79       921\n",
      "       other       0.91      0.66      0.76       536\n",
      "\n",
      "    accuracy                           0.75      1933\n",
      "   macro avg       0.68      0.75      0.70      1933\n",
      "weighted avg       0.78      0.75      0.76      1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all question类别打标之后的\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d5cd8-4f78-4ecf-9092-4fb053996156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b3afb84-84f5-4f2e-8527-7eb3f29b6b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 927, 'other': 389, 'error': 311, 'deployment': 210, 'performance': 96})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.59      0.86      0.70       211\n",
      " performance       0.38      0.80      0.51        45\n",
      "  deployment       0.38      0.70      0.49       115\n",
      "    question       0.84      0.71      0.77      1095\n",
      "       other       0.79      0.66      0.71       467\n",
      "\n",
      "    accuracy                           0.71      1933\n",
      "   macro avg       0.59      0.74      0.64      1933\n",
      "weighted avg       0.76      0.71      0.72      1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all other类别打标之后的\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac5a77-3b18-4b78-a5e8-c815eec40b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bab3db-62d4-4849-beb1-85f69bc05488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf62059-ad41-4652-9410-42038493d52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dccc130-84ac-4cf4-b2cf-3a3bb180f357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 927, 'other': 389, 'error': 311, 'deployment': 210, 'performance': 96})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.52      0.87      0.65       188\n",
      " performance       0.31      0.79      0.45        38\n",
      "  deployment       0.27      0.73      0.39        77\n",
      "    question       0.78      0.69      0.73      1054\n",
      "       other       0.79      0.53      0.63       576\n",
      "\n",
      "    accuracy                           0.66      1933\n",
      "   macro avg       0.53      0.72      0.57      1933\n",
      "weighted avg       0.73      0.66      0.67      1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all 看一下修改deploymdent类别定义之后的影响，对于question类别\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96079d0d-364a-461e-a567-cce201c360d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26667ae1-a966-4c7f-86bd-3aeb11292f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 815, 'other': 365, 'error': 326, 'deployment': 312, 'performance': 115})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.51      0.89      0.65       188\n",
      " performance       0.30      0.89      0.44        38\n",
      "  deployment       0.23      0.92      0.37        77\n",
      "    question       0.78      0.60      0.68      1054\n",
      "       other       0.80      0.51      0.62       576\n",
      "\n",
      "    accuracy                           0.62      1933\n",
      "   macro avg       0.52      0.76      0.55      1933\n",
      "weighted avg       0.73      0.62      0.64      1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2960c8-1814-4702-90e8-a9e07c9d3870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80b7fb8-5f3b-417f-bfb3-b8c217bb9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 815, 'other': 365, 'error': 326, 'deployment': 312, 'performance': 115})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.49      0.67      0.57       240\n",
      " performance       0.23      0.79      0.35        33\n",
      "  deployment       0.18      0.79      0.29        70\n",
      "    question       0.77      0.60      0.67      1038\n",
      "       other       0.75      0.50      0.60       552\n",
      "\n",
      "    accuracy                           0.59      1933\n",
      "   macro avg       0.48      0.67      0.50      1933\n",
      "weighted avg       0.70      0.59      0.62      1933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fb4e6-7baf-4979-9a99-da661bee097a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9586e8-379a-4d42-b623-76e762c226af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ec10498-7f28-4aba-96e0-3f9f377d0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 557, 'error': 167, 'deployment': 155, 'performance': 69, 'other': 55})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.00      0.00      0.00         0\n",
      " performance       0.00      0.00      0.00         0\n",
      "  deployment       0.00      0.00      0.00         0\n",
      "    question       1.00      0.56      0.71      1003\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56      1003\n",
      "   macro avg       0.20      0.11      0.14      1003\n",
      "weighted avg       1.00      0.56      0.71      1003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# question\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f73b5bb-b653-4c8a-936f-0b6e159f4283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9f34c-f469-49f9-8aa4-2dceb0f256de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d492e1-2a74-4c43-a92f-10dc8f249e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'question': 418, 'deployment': 323, 'error': 120, 'other': 76, 'performance': 66})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.00      0.00      0.00         0\n",
      " performance       0.00      0.00      0.00         0\n",
      "  deployment       0.00      0.00      0.00         0\n",
      "    question       1.00      0.42      0.59      1003\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.42      1003\n",
      "   macro avg       0.20      0.08      0.12      1003\n",
      "weighted avg       1.00      0.42      0.59      1003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46992be-cc44-4259-8bc9-99a1e088e7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15271f9-4900-4e04-81c5-763e514f6087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c40a9d-78e3-4a2b-b6b1-e966422703ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170109ec-d05e-4d36-a144-d2d1c0f0cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'error': 146, 'deployment': 35, 'other': 20, 'performance': 15, 'question': 6})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       1.00      0.66      0.79       222\n",
      " performance       0.00      0.00      0.00         0\n",
      "  deployment       0.00      0.00      0.00         0\n",
      "    question       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.66       222\n",
      "   macro avg       0.20      0.13      0.16       222\n",
      "weighted avg       1.00      0.66      0.79       222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# error\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec9806-b8ab-43ff-b832-b451f0ac8790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf1715-70c7-4bfa-87e4-621b0de8f937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622ca19-499f-455c-9f20-5e5ddd0eda20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8da50eb8-0e61-4282-a023-f898bb987a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'deployment': 48, 'error': 41, 'performance': 34, 'question': 32, 'other': 10})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.00      0.00      0.00         0\n",
      " performance       0.76      0.47      0.58        55\n",
      "  deployment       0.94      0.41      0.57       110\n",
      "    question       0.00      0.00      0.00         0\n",
      "       other       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       165\n",
      "   macro avg       0.34      0.18      0.23       165\n",
      "weighted avg       0.88      0.43      0.57       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# deployment performance\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f41f5e-2d8b-4133-bcc8-e90486ef1f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba56199-f82f-4aa6-b5b4-059300be6b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ace61109-826c-4f9a-ba95-89b47e348b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'other': 267, 'question': 150, 'error': 51, 'deployment': 44, 'performance': 29, 'feature': 2})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       error       0.00      0.00      0.00         0\n",
      " performance       0.00      0.00      0.00         0\n",
      "  deployment       0.00      0.00      0.00         0\n",
      "    question       0.00      0.00      0.00         0\n",
      "       other       1.00      0.50      0.66       543\n",
      "\n",
      "    accuracy                           0.50       543\n",
      "   macro avg       0.20      0.10      0.13       543\n",
      "weighted avg       1.00      0.50      0.66       543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# other\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(pred_labels))\n",
    "origin_labels = [x.lower() for x in origin_labels]\n",
    "pred_labels = [x.lower() for x in pred_labels]\n",
    "tmp_pred_labels = []\n",
    "for x in pred_labels:\n",
    "    if x not in [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]:\n",
    "        x = 'other'\n",
    "    tmp_pred_labels.append(x)\n",
    "pred_labels = tmp_pred_labels\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "labels = [\"error\", \"performance\", \"deployment\", \"question\", \"other\"]\n",
    "label_map = {\n",
    "    \"error\": 0, \n",
    "    \"performance\": 1,\n",
    "    \"deployment\": 2,\n",
    "    \"question\": 3,\n",
    "    \"other\": 4\n",
    "}\n",
    "final_origin_labels_num = [label_map[l] for l in origin_labels]\n",
    "final_pred_labels_num = [label_map[l] for l in pred_labels]\n",
    "\n",
    "report = classification_report(final_origin_labels_num, final_pred_labels_num, target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaef0c9-a6f0-42d5-ba0d-d2700c0bb423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d4c24-7e96-4115-984c-ea2f52db3d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605b98b-10ae-4306-972c-a3ca82f654f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### **Category: other**\n",
    "\n",
    "The **other** category is reserved for issues, feature requests, or discussions that extend beyond the scope of core functionality errors, performance bottlenecks, deployment challenges, or user misunderstandings. It emphasizes improving or expanding the repository’s overall usability and scope.  \n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Suggestions for new functionalities or improvements to existing features.  \n",
    "\n",
    "2. **Documentation Enhancements**  \n",
    "   Proposals to clarify or expand guides, examples, or API references.  \n",
    "\n",
    "3. **Infrastructure Discussions**  \n",
    "   Conversations about updates or optimizations related to build systems, CI/CD pipelines, or configurations.  \n",
    "\n",
    "4. **Design and Workflow Improvements**  \n",
    "   Suggestions to enhance user interfaces, collaboration workflows, or general feature designs.  \n",
    "\n",
    "5. **Experimental Features**  \n",
    "   Feedback or ideas for testing and refining experimental functionalities.  \n",
    "\n",
    "6. **Non-Functional Enhancements**  \n",
    "   Improvements in areas like logging, visual interfaces, or optional settings.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb66c2-19fe-49ac-b27d-07c6caf26153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "### **Category: other**\n",
    "\n",
    "The **other** category is used for issues, feature requests, or discussions that do not align directly with errors, performance bottlenecks, or deployment challenges. It emphasizes proposals, suggestions, or improvements aimed at enhancing the repository's overall functionality, usability, or user experience.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Suggestions for adding new features, tools, or functionalities to the repository.  \n",
    "\n",
    "2. **Documentation Enhancements**  \n",
    "   Proposals to improve guides, examples, API references, or overall clarity in documentation.  \n",
    "\n",
    "3. **Infrastructure Discussions**  \n",
    "   Topics related to optimizing workflows, build systems, CI/CD pipelines, or other infrastructural components.  \n",
    "\n",
    "4. **Design and Workflow Suggestions**  \n",
    "   Ideas to improve user interfaces, streamline collaboration workflows, or refine existing designs.  \n",
    "\n",
    "5. **Experimental Features**  \n",
    "   Feedback or recommendations for testing, refining, or introducing experimental functionalities.  \n",
    "\n",
    "6. **Usability Enhancements**  \n",
    "   Improvements related to visual interfaces, optional configurations, or debugging aids like better error messages or logging.  \n",
    "\n",
    "7. **Community and Support Proposals**  \n",
    "   Suggestions to improve community engagement, such as adding demos, examples, or resources for easier onboarding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2095d1-4f87-4046-bb64-9b3677354d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: other**\n",
    "\n",
    "The **other** category encompasses issues, feature requests, or discussions that are not directly related to errors, performance bottlenecks, deployment challenges, or user misunderstandings. This category focuses on general enhancements, community-driven proposals, or infrastructural improvements aimed at enriching the repository's overall ecosystem.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Enhancements**  \n",
    "   Suggestions for adding new functionalities, improving existing features, or modifying workflows to better align with user needs.\n",
    "\n",
    "2. **Documentation Updates**  \n",
    "   Proposals to improve guides, tutorials, API references, or other forms of documentation to enhance clarity and usability.\n",
    "\n",
    "3. **Community Contributions**  \n",
    "   Discussions or requests related to promoting community engagement, such as creating demos, localization efforts, or building partnerships.\n",
    "\n",
    "4. **Infrastructure Optimizations**  \n",
    "   Topics on improving build systems, CI/CD pipelines, dependency management, or repository structure.\n",
    "\n",
    "5. **Design Proposals**  \n",
    "   Ideas for improving user interfaces, streamlining collaboration processes, or refining existing designs for better usability.\n",
    "\n",
    "6. **General Usability Enhancements**  \n",
    "   Requests or feedback related to improving debugging tools, error messages, optional configurations, or adding utilities for developer productivity.\n",
    "\n",
    "7. **Support for Emerging Technologies**  \n",
    "   Requests to adapt the repository for new platforms, tools, or standards in line with technological advancements.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a46f4e-9c85-4c84-be01-28f41f9abc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category encompasses topics or discussions that do not directly align with errors, performance bottlenecks, deployment challenges, or user misunderstandings. It focuses on broader aspects that enrich the repository's ecosystem, usability, or functionality.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Suggestions for new functionalities, enhanced tools, or modifications to existing workflows that align with user needs or technological trends.\n",
    "\n",
    "2. **Usability Enhancements**  \n",
    "   Proposals to improve accessibility, UI/UX, or interaction flows within the repository.\n",
    "\n",
    "3. **Design Improvements**  \n",
    "   Ideas for refining visual design, layout, or branding elements to align with modern standards or project goals.\n",
    "\n",
    "4. **Documentation Updates**  \n",
    "   Requests or contributions to enhance clarity, add examples, or expand explanations in guides, API references, or tutorials.\n",
    "\n",
    "5. **Community Engagement**  \n",
    "   Initiatives aimed at fostering collaboration, such as organizing localization efforts, promoting best practices, or facilitating external contributions.\n",
    "\n",
    "6. **Infrastructure and Tooling Improvements**  \n",
    "   Enhancements to build systems, CI/CD pipelines, dependency management, or repository structure for smoother development processes.\n",
    "\n",
    "7. **Support for Emerging Technologies**  \n",
    "   Discussions or requests to adapt the repository to new tools, platforms, or standards in line with advancements in the field.\n",
    "\n",
    "8. **General Suggestions**  \n",
    "   Feedback, exploratory ideas, or speculative discussions that do not fit into other predefined categories.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526a2ef-316e-4596-bb48-76c3f412b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category captures topics or discussions that extend beyond specific technical errors, performance challenges, deployment processes, or direct user misunderstandings. It includes issues that enhance the repository's overall ecosystem, functionality, and accessibility.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Proposals for new functionalities, improved tools, or modifications to existing workflows aligned with user needs or emerging technologies.\n",
    "\n",
    "2. **Documentation Enhancements**  \n",
    "   Suggestions to improve clarity, structure, or accessibility of guides, API references, or tutorials, as well as adding illustrative examples or expanding explanations.\n",
    "\n",
    "3. **Design and Usability Improvements**  \n",
    "   Ideas to refine UI/UX design, interaction flows, or the overall accessibility of the repository's features.\n",
    "\n",
    "4. **Infrastructure and Tooling Improvements**  \n",
    "   Discussions about refining CI/CD pipelines, dependency management, build systems, or other infrastructural elements that enhance development processes.\n",
    "\n",
    "5. **Community and Collaboration Initiatives**  \n",
    "   Efforts to foster community engagement, such as localization, promoting best practices, or encouraging external contributions.\n",
    "\n",
    "6. **Integration and Compatibility Discussions**  \n",
    "   Requests or ideas for compatibility with external tools, libraries, or platforms to align the repository with broader industry trends.\n",
    "\n",
    "7. **General Feedback or Suggestions**  \n",
    "   Exploratory ideas, speculative discussions, or feedback that doesn’t fit into other predefined categories but contribute to the repository's growth and improvement.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83635627-ab65-4689-bf6b-4e9b0871006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category encompasses discussions and issues that contribute to the broader functionality, usability, or ecosystem of the repository, which do not align specifically with errors, performance bottlenecks, deployment challenges, or user misunderstandings.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Suggestions for new tools, enhancements to existing features, or additional functionalities to meet user needs or improve workflows.\n",
    "\n",
    "2. **Documentation Updates**  \n",
    "   Requests or ideas for improving guides, API references, tutorials, or adding examples for better understanding.\n",
    "\n",
    "3. **Design and Usability Enhancements**  \n",
    "   Proposals to refine user interface design, improve user experience, or enhance the accessibility of repository features.\n",
    "\n",
    "4. **Infrastructure and Tooling Improvements**  \n",
    "   Discussions related to optimizing CI/CD pipelines, dependency management, or development tooling for better efficiency.\n",
    "\n",
    "5. **Community Engagement and Collaboration**  \n",
    "   Initiatives to strengthen community interaction, promote best practices, or encourage contributions, including surveys or outreach efforts.\n",
    "\n",
    "6. **Integration and Compatibility Enhancements**  \n",
    "   Ideas for expanding compatibility with external tools, platforms, or libraries to align with evolving industry standards.\n",
    "\n",
    "7. **Exploratory Ideas and General Feedback**  \n",
    "   Speculative discussions, broad feedback, or exploratory suggestions for the repository's growth that don’t fit into predefined categories.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80108ab6-6663-4e37-a63c-63c0aa057c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category encompasses topics, discussions, and suggestions that enhance the overall functionality, usability, or ecosystem of the repository but do not align with specific categories such as errors, performance bottlenecks, deployment challenges, or user misunderstandings.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Proposals for adding new features, enhancing existing functionality, or introducing tools to meet user needs or improve workflows.\n",
    "\n",
    "2. **Documentation Updates**  \n",
    "   Suggestions for improving guides, tutorials, API references, or examples for better user understanding and accessibility.\n",
    "\n",
    "3. **Design and Usability Improvements**  \n",
    "   Ideas to refine the user interface, improve user experience, or enhance accessibility.\n",
    "\n",
    "4. **Infrastructure and Tooling Enhancements**  \n",
    "   Discussions related to improving CI/CD pipelines, dependency management, or developer tools to streamline efficiency.\n",
    "\n",
    "5. **Community Engagement Initiatives**  \n",
    "   Activities or strategies aimed at fostering collaboration, promoting best practices, or encouraging contributions.\n",
    "\n",
    "6. **Integration and Compatibility Suggestions**  \n",
    "   Proposals for expanding support or compatibility with external tools, platforms, or libraries.\n",
    "\n",
    "7. **General Feedback and Speculative Ideas**  \n",
    "   Broad feedback, exploratory discussions, or speculative suggestions for the repository's growth and future directions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b5174-cf22-4595-a5ae-d3cac9e7eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category includes discussions, requests, and suggestions that enhance the functionality, usability, or ecosystem of the repository but do not align with specific categories like errors, performance, deployment, or user misunderstandings. This category serves as a flexible space for improvements, expansions, and feedback.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Proposals for introducing new features, improving existing ones, or integrating tools to meet user needs or enhance workflows.\n",
    "\n",
    "2. **Documentation Enhancements**  \n",
    "   Suggestions for improving guides, tutorials, API references, or examples to improve user accessibility and comprehension.\n",
    "\n",
    "3. **Design and Usability Improvements**  \n",
    "   Ideas to refine user interfaces, enhance user experience, or improve accessibility for diverse audiences.\n",
    "\n",
    "4. **Infrastructure and Tooling Upgrades**  \n",
    "   Discussions on improving CI/CD pipelines, dependency management, or developer tools to streamline project efficiency.\n",
    "\n",
    "5. **Community Building and Engagement**  \n",
    "   Initiatives or strategies aimed at encouraging collaboration, fostering best practices, or expanding community involvement.\n",
    "\n",
    "6. **Integration and Compatibility Enhancements**  \n",
    "   Suggestions to expand support for or compatibility with external tools, platforms, or libraries.\n",
    "\n",
    "7. **Feedback and Growth Ideas**  \n",
    "   Broad feedback, speculative discussions, or ideas aimed at the long-term growth and direction of the repository.\n",
    "\n",
    "8. **Experimental or Prototype Proposals**  \n",
    "   Requests or discussions about experimental features or prototype implementations to explore new capabilities.\n",
    "\n",
    "9. **Process and Workflow Suggestions**  \n",
    "   Proposals to optimize development workflows, contribution guidelines, or operational processes.\n",
    "\n",
    "10. **Policy or Licensing Questions**  \n",
    "   Inquiries or proposals regarding repository policies, licensing, or governance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283228d4-3eb3-40bc-bc83-96fd2d1ac038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### **Category: Other**\n",
    "\n",
    "The **other** category encompasses discussions, requests, and suggestions that contribute to enhancing the repository's functionality, usability, ecosystem, or community engagement. These do not fall into the more specific categories of errors, performance issues, deployment challenges, or misunderstandings but are nonetheless critical to the repository's growth and user experience.\n",
    "\n",
    "#### **Basic Definition**:\n",
    "This category is a flexible space for contributions, feedback, and discussions that address aspects of the repository beyond immediate technical concerns or coding issues.\n",
    "\n",
    "#### **Includes**:\n",
    "1. **Feature Requests**  \n",
    "   Proposals for adding new features, improving existing functionalities, or integrating tools to meet evolving user needs.\n",
    "\n",
    "2. **Documentation Enhancements**  \n",
    "   Suggestions for improving guides, tutorials, examples, or API references to facilitate better understanding and accessibility for users.\n",
    "\n",
    "3. **Design and Usability Improvements**  \n",
    "   Ideas to refine interfaces, improve user workflows, or enhance accessibility for a diverse range of users.\n",
    "\n",
    "4. **Infrastructure and Tooling Discussions**  \n",
    "   Feedback or suggestions about CI/CD pipelines, dependency management, or developer tools to improve development efficiency.\n",
    "\n",
    "5. **Community Building and Engagement**  \n",
    "   Initiatives or discussions aimed at fostering collaboration, expanding user contributions, or enhancing the repository's community dynamics.\n",
    "\n",
    "6. **Integration and Compatibility**  \n",
    "   Suggestions or discussions on ensuring compatibility with external tools, platforms, or libraries.\n",
    "\n",
    "7. **Feedback on Growth and Vision**  \n",
    "   Broad feedback or strategic suggestions focused on the repository's long-term growth, direction, and innovation.\n",
    "\n",
    "8. **Experimental and Prototyping Ideas**  \n",
    "   Discussions or requests to explore experimental features or prototype implementations to test new capabilities.\n",
    "\n",
    "9. **Process and Workflow Optimization**  \n",
    "   Proposals for improving operational processes, contribution guidelines, or development workflows.\n",
    "\n",
    "10. **Policy and Licensing Discussions**  \n",
    "    Inquiries or suggestions regarding the repository's licensing, governance, or operational policies.\n",
    "\n",
    "11. **General Support and Queries**  \n",
    "    User inquiries seeking clarification or guidance on using the repository, understanding its structure, or exploring its capabilities, when not directly related to errors or technical performance.\n",
    "\n",
    "12. **Platform and Ecosystem Expansion**  \n",
    "    Requests or discussions about extending the repository's use cases, such as adapting for new platforms, datasets, or scenarios.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4498404-0445-421f-b009-fb5ab26b7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Revised Definition for the **Other** Category (Enhanced)\n",
    "\n",
    "**Category: Other**\n",
    "\n",
    "The **other** category encompasses discussions, requests, and suggestions that contribute to enhancing the repository's functionality, usability, ecosystem, or community engagement. This category is a flexible space for contributions, feedback, and queries that do not fit neatly into specific categories such as errors, performance issues, deployment challenges, or misunderstandings. Its purpose is to capture and support discussions that address broader aspects of repository growth, strategy, and user experience.\n",
    "\n",
    "#### **Basic Definition**\n",
    "The **other** category includes topics that enhance the repository beyond direct code issues, focusing on broader improvements, strategic directions, or community-driven enhancements.\n",
    "\n",
    "#### **Includes**\n",
    "1. **Feature Requests**\n",
    "   - Suggestions for adding new capabilities, tools, or functionalities.\n",
    "   - Enhancements to existing features to meet evolving user needs.\n",
    "\n",
    "2. **Documentation and Educational Content**\n",
    "   - Proposals for creating or improving guides, tutorials, examples, or API references.\n",
    "   - Requests for detailed explanations or additional clarification on existing materials.\n",
    "\n",
    "3. **Design and Usability Enhancements**\n",
    "   - Ideas for refining interfaces, improving workflows, or boosting accessibility.\n",
    "\n",
    "4. **Infrastructure and Tooling Feedback**\n",
    "   - Suggestions to improve CI/CD pipelines, dependency management, or development tools.\n",
    "   - Recommendations for better compatibility with third-party integrations.\n",
    "\n",
    "5. **Community Building and Collaboration**\n",
    "   - Discussions to foster community engagement, user contributions, and collaborative initiatives.\n",
    "   - Requests for new communication channels, such as forums, Slack, or gitter.\n",
    "\n",
    "6. **Integration and Ecosystem Expansion**\n",
    "   - Requests for ensuring compatibility with external tools, platforms, datasets, or libraries.\n",
    "   - Proposals to extend repository use cases to new domains.\n",
    "\n",
    "7. **Feedback on Repository Vision and Growth**\n",
    "   - Strategic suggestions for long-term growth and innovation.\n",
    "   - Contributions aiming to align with the broader goals of the repository.\n",
    "\n",
    "8. **Experimental and Prototyping Proposals**\n",
    "   - Discussions around testing new features, experimental ideas, or prototype implementations.\n",
    "\n",
    "9. **Process and Workflow Improvements**\n",
    "   - Suggestions for optimizing contribution guidelines, issue triaging, or development processes.\n",
    "\n",
    "10. **Policy and Licensing Inquiries**\n",
    "    - Requests for clarification or suggestions regarding repository governance, licensing, or policies.\n",
    "\n",
    "11. **General Support and Queries**\n",
    "    - Inquiries for assistance or clarification not tied directly to technical issues.\n",
    "    - Questions that span multiple areas of functionality or repository design.\n",
    "\n",
    "12. **Platform and Feature Expansion**\n",
    "    - Discussions about adapting the repository for new use cases, languages, or platforms.\n",
    "    - Requests for additional datasets, pretrained models, or resource-specific enhancements.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250d2a0-11a2-4344-93fa-00f25aeef249",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Revised Definition for the **Other** Category (Expanded and Enhanced)\n",
    "\n",
    "**Category: Other**\n",
    "\n",
    "The **other** category is a flexible and inclusive classification designed to capture issues, discussions, and contributions that do not fall into specific predefined categories such as errors, performance problems, deployment challenges, or questions about repository functionality. This category encompasses a broad range of topics aimed at enhancing the repository's overall ecosystem, usability, and engagement.\n",
    "\n",
    "#### **Basic Definition**\n",
    "The **other** category includes topics that address broader improvements, strategic discussions, feature suggestions, or general contributions that contribute to the repository's growth and user experience.\n",
    "\n",
    "#### **Includes**\n",
    "1. **Feature Requests and Enhancements**\n",
    "   - Suggestions for adding new capabilities, tools, or functionalities.\n",
    "   - Proposals for refining or improving existing features to better meet user needs.\n",
    "\n",
    "2. **Documentation Improvements**\n",
    "   - Requests for creating or enhancing guides, tutorials, examples, or reference materials.\n",
    "   - Proposals for clarifying or expanding on existing documentation.\n",
    "\n",
    "3. **Design and Usability Proposals**\n",
    "   - Suggestions to improve interfaces, workflows, or accessibility.\n",
    "   - Feedback on design elements to enhance the user experience.\n",
    "\n",
    "4. **Community and Collaboration Initiatives**\n",
    "   - Discussions to foster user engagement, community building, and collaborative efforts.\n",
    "   - Proposals for creating new communication channels or improving existing ones.\n",
    "\n",
    "5. **Integration and Compatibility Feedback**\n",
    "   - Suggestions for ensuring compatibility with external tools, platforms, datasets, or APIs.\n",
    "   - Requests for extending repository support to new environments, domains, or use cases.\n",
    "\n",
    "6. **Strategic Vision and Growth**\n",
    "   - Contributions that align with the long-term goals and innovative direction of the repository.\n",
    "   - Feedback on roadmaps, priorities, and potential areas of expansion.\n",
    "\n",
    "7. **Infrastructure and Tooling**\n",
    "   - Proposals to improve CI/CD pipelines, dependency management, or development workflows.\n",
    "   - Feedback on compatibility with specific hardware, software versions, or third-party integrations.\n",
    "\n",
    "8. **Educational and Training Resources**\n",
    "   - Requests for or contributions of resources such as training datasets, model examples, or educational tools.\n",
    "   - Proposals for expanding the repository's educational outreach or training capabilities.\n",
    "\n",
    "9. **Experimental Ideas and Prototyping**\n",
    "   - Discussions around testing new concepts, experimental features, or prototype implementations.\n",
    "   - Feedback on experimental releases or beta testing results.\n",
    "\n",
    "10. **Policy, Licensing, and Governance**\n",
    "    - Inquiries or feedback regarding the repository's policies, licensing terms, or governance structure.\n",
    "    - Suggestions for enhancing transparency or community-driven decision-making.\n",
    "\n",
    "11. **Platform Expansion and Ecosystem Building**\n",
    "    - Requests or suggestions to adapt the repository for additional platforms, languages, or use cases.\n",
    "    - Feedback on building a robust ecosystem around the repository.\n",
    "\n",
    "12. **General Inquiries and Support**\n",
    "    - Questions or requests that span multiple areas of functionality or require broader context.\n",
    "    - Topics that do not fit neatly into a single category but contribute to the repository's growth.\n",
    "\n",
    "13. **Process and Workflow Optimization**\n",
    "    - Suggestions for improving contribution guidelines, issue triaging, or developer onboarding.\n",
    "    - Proposals to streamline processes for better collaboration and efficiency.\n",
    "\n",
    "14. **Feedback on Timeliness and Engagement**\n",
    "    - Suggestions for improving the responsiveness of issue resolutions or community interactions.\n",
    "    - Requests for updates on roadmap progress or feature development timelines.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe01277-90c5-4fed-a06f-636c0cd866b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Revised Definition for the **Other** Category (Comprehensive and Inclusive)\n",
    "\n",
    "**Category: Other**\n",
    "\n",
    "The **Other** category is a flexible classification designed to encompass a broad range of issues, discussions, or contributions that do not fall neatly into predefined categories such as errors, performance problems, deployment issues, or user questions. This category is essential for ensuring that all valuable input contributing to the repository's growth, usability, or functionality is acknowledged and addressed appropriately.\n",
    "\n",
    "#### **Basic Definition**\n",
    "The **Other** category includes any topics that focus on enhancements, strategic considerations, feature suggestions, or contributions that improve the repository's ecosystem, capabilities, or community engagement.\n",
    "\n",
    "#### **Includes**\n",
    "1. **Feature Requests and Enhancements**\n",
    "   - Suggestions for new tools, functionalities, or capabilities.\n",
    "   - Proposals to refine or improve existing features to better serve user needs.\n",
    "\n",
    "2. **Documentation and Educational Resources**\n",
    "   - Requests for creating or improving guides, tutorials, or reference materials.\n",
    "   - Suggestions for adding clarity or expanding the existing documentation to enhance usability.\n",
    "   - Proposals for new training datasets or educational tools related to the repository.\n",
    "\n",
    "3. **Design and Usability Improvements**\n",
    "   - Feedback on user experience, workflows, or interface accessibility.\n",
    "   - Suggestions for improving the design or usability of existing features.\n",
    "\n",
    "4. **Community and Collaboration Initiatives**\n",
    "   - Proposals to foster community engagement and collaboration.\n",
    "   - Discussions on creating or improving communication channels or community governance structures.\n",
    "\n",
    "5. **Strategic Discussions and Vision**\n",
    "   - Contributions aligning with long-term goals or innovative directions for the repository.\n",
    "   - Feedback on roadmaps, priorities, and expansion opportunities.\n",
    "\n",
    "6. **Integration and Compatibility**\n",
    "   - Suggestions for improving compatibility with external tools, platforms, datasets, or APIs.\n",
    "   - Requests to adapt the repository for specific environments, hardware, or use cases.\n",
    "\n",
    "7. **Experimental Features and Prototyping**\n",
    "   - Discussions about testing new concepts or experimental features.\n",
    "   - Feedback on beta releases or prototype implementations.\n",
    "\n",
    "8. **Infrastructure, CI/CD, and Tooling**\n",
    "   - Proposals to enhance build systems, testing pipelines, or development workflows.\n",
    "   - Feedback on optimizing the repository's infrastructure or supporting tools.\n",
    "\n",
    "9. **Policy, Licensing, and Governance**\n",
    "   - Inquiries or feedback on policies, licensing terms, or governance.\n",
    "   - Suggestions to improve transparency or user collaboration in decision-making.\n",
    "\n",
    "10. **Dataset Availability and Ethical Concerns**\n",
    "    - Discussions about accessibility and availability of critical datasets.\n",
    "    - Feedback on ethical considerations related to the repository or associated technologies.\n",
    "\n",
    "11. **Platform and Ecosystem Expansion**\n",
    "    - Proposals to extend the repository's functionality to additional platforms, programming languages, or ecosystems.\n",
    "    - Feedback on ecosystem-building efforts around the repository.\n",
    "\n",
    "12. **General Contributions and Support**\n",
    "    - Contributions that span multiple categories or do not fit into a specific predefined area.\n",
    "    - General feedback aimed at improving repository processes or user engagement.\n",
    "\n",
    "13. **Feedback on Community Timeliness and Responsiveness**\n",
    "    - Suggestions to improve the speed of issue resolution or feature implementation.\n",
    "    - Requests for updates on roadmap milestones or development progress.\n",
    "\n",
    "14. **Broad Improvement Proposals**\n",
    "    - Discussions aimed at enhancing repository structure, communication, or inclusivity.\n",
    "    - Suggestions that influence the overall growth or usability of the repository.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca741f-7a82-4f69-9c38-31853cb788e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### Revised Definition for the **Other** Category\n",
    "\n",
    "- **Other**: \n",
    "    1. Topics that do not fall under any predefined category.\n",
    "    2. Issues or discussions unrelated to the repository, such as general inquiries, off-topic discussions, or irrelevant submissions.\n",
    "\n",
    "\n",
    "    #### **Includes**\n",
    "    1. **Feature Development and Testing**\n",
    "       - Suggestions for new functionalities, enhancements, or prototypes.\n",
    "       - Feedback on beta features or experimental implementations.\n",
    "    \n",
    "    2. **Documentation, Resources, and Ethical Concerns**\n",
    "       - Proposals for improving guides, tutorials, or reference materials.\n",
    "       - Discussions on dataset accessibility, ethical considerations, and educational tools.\n",
    "    \n",
    "    3. **User Experience and Compatibility**\n",
    "       - Suggestions for improving design, usability, and interface accessibility.\n",
    "       - Feedback on compatibility with external tools, platforms, and APIs.\n",
    "    \n",
    "    4. **Community and Collaboration**\n",
    "       - Proposals to improve community engagement, governance, and responsiveness.\n",
    "       - Feedback on collaboration tools and communication channels.\n",
    "    \n",
    "    5. **Strategy and Ecosystem Development**\n",
    "       - Contributions aligning with long-term goals, roadmaps, or ecosystem expansion.\n",
    "       - Discussions on strategic priorities and platform integration opportunities.\n",
    "    \n",
    "    6. **Infrastructure and Governance**\n",
    "       - Suggestions for improving build systems, CI/CD pipelines, or development workflows.\n",
    "       - Feedback on policies, licensing, and governance structures.\n",
    "    \n",
    "    7. **Broad Improvement Proposals**\n",
    "       - Contributions focused on enhancing repository structure, inclusivity, or communication.\n",
    "       - Suggestions with overarching impact on repository growth and usability.\n",
    "    \n",
    "    8. **Miscellaneous Contributions**\n",
    "       - Topics that add value to the repository but do not fit into predefined categories.\n",
    "       - Issues unrelated to the repository’s purpose, including off-topic or irrelevant submissions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39734c23-c8ae-4808-8cf8-020a5bfd6f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
